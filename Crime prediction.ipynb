{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "90"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1: Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv(\"../Crime Prediction Data/communities-crime-clean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>communityname</th>\n",
       "      <th>fold</th>\n",
       "      <th>population</th>\n",
       "      <th>householdsize</th>\n",
       "      <th>racepctblack</th>\n",
       "      <th>racePctWhite</th>\n",
       "      <th>racePctAsian</th>\n",
       "      <th>racePctHisp</th>\n",
       "      <th>agePct12t21</th>\n",
       "      <th>...</th>\n",
       "      <th>PctForeignBorn</th>\n",
       "      <th>PctBornSameState</th>\n",
       "      <th>PctSameHouse85</th>\n",
       "      <th>PctSameCity85</th>\n",
       "      <th>PctSameState85</th>\n",
       "      <th>LandArea</th>\n",
       "      <th>PopDens</th>\n",
       "      <th>PctUsePubTrans</th>\n",
       "      <th>LemasPctOfficDrugUn</th>\n",
       "      <th>ViolentCrimesPerPop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Alabastercity</td>\n",
       "      <td>7</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.41</td>\n",
       "      <td>...</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>AlexanderCitycity</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.47</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Annistoncity</td>\n",
       "      <td>3</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.41</td>\n",
       "      <td>...</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Athenscity</td>\n",
       "      <td>8</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.39</td>\n",
       "      <td>...</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Auburncity</td>\n",
       "      <td>1</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.02</td>\n",
       "      <td>1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>Bessemercity</td>\n",
       "      <td>6</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.44</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.43</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>Birminghamcity</td>\n",
       "      <td>2</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.37</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.41</td>\n",
       "      <td>...</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.38</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>Cullmancity</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.38</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>Daphnecity</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.35</td>\n",
       "      <td>...</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>Decaturcity</td>\n",
       "      <td>10</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.39</td>\n",
       "      <td>...</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 104 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   state      communityname  fold  population  householdsize  racepctblack  \\\n",
       "0      1      Alabastercity     7        0.01           0.61          0.21   \n",
       "1      1  AlexanderCitycity    10        0.01           0.41          0.55   \n",
       "2      1       Annistoncity     3        0.03           0.34          0.86   \n",
       "3      1         Athenscity     8        0.01           0.38          0.35   \n",
       "4      1         Auburncity     1        0.04           0.37          0.32   \n",
       "5      1       Bessemercity     6        0.04           0.44          1.00   \n",
       "6      1     Birminghamcity     2        0.41           0.37          1.00   \n",
       "7      1        Cullmancity     1        0.01           0.30          0.00   \n",
       "8      1         Daphnecity     7        0.00           0.39          0.31   \n",
       "9      1        Decaturcity    10        0.06           0.39          0.32   \n",
       "\n",
       "   racePctWhite  racePctAsian  racePctHisp  agePct12t21         ...           \\\n",
       "0          0.83          0.02         0.01         0.41         ...            \n",
       "1          0.57          0.01         0.00         0.47         ...            \n",
       "2          0.30          0.04         0.01         0.41         ...            \n",
       "3          0.71          0.04         0.01         0.39         ...            \n",
       "4          0.70          0.21         0.02         1.00         ...            \n",
       "5          0.10          0.00         0.00         0.43         ...            \n",
       "6          0.02          0.03         0.01         0.41         ...            \n",
       "7          0.99          0.02         0.01         0.38         ...            \n",
       "8          0.75          0.02         0.02         0.35         ...            \n",
       "9          0.73          0.04         0.01         0.39         ...            \n",
       "\n",
       "   PctForeignBorn  PctBornSameState  PctSameHouse85  PctSameCity85  \\\n",
       "0            0.03              0.70            0.40           0.34   \n",
       "1            0.00              0.93            0.66           0.82   \n",
       "2            0.04              0.77            0.59           0.70   \n",
       "3            0.03              0.78            0.56           0.67   \n",
       "4            0.12              0.49            0.12           0.00   \n",
       "5            0.00              0.96            0.74           0.95   \n",
       "6            0.03              0.90            0.64           0.86   \n",
       "7            0.00              0.82            0.54           0.72   \n",
       "8            0.03              0.60            0.46           0.40   \n",
       "9            0.03              0.71            0.47           0.61   \n",
       "\n",
       "   PctSameState85  LandArea  PopDens  PctUsePubTrans  LemasPctOfficDrugUn  \\\n",
       "0            0.57      0.05     0.06            0.01                 0.00   \n",
       "1            0.84      0.11     0.03            0.01                 0.00   \n",
       "2            0.64      0.06     0.11            0.04                 0.00   \n",
       "3            0.71      0.09     0.05            0.00                 0.00   \n",
       "4            0.15      0.09     0.09            0.01                 0.00   \n",
       "5            0.89      0.11     0.07            0.13                 0.00   \n",
       "6            0.82      0.43     0.15            0.20                 0.38   \n",
       "7            0.76      0.04     0.07            0.01                 0.00   \n",
       "8            0.54      0.03     0.08            0.01                 0.00   \n",
       "9            0.60      0.14     0.09            0.01                 0.00   \n",
       "\n",
       "   ViolentCrimesPerPop  \n",
       "0                 0.06  \n",
       "1                 0.14  \n",
       "2                 1.00  \n",
       "3                 0.23  \n",
       "4                 0.15  \n",
       "5                 1.00  \n",
       "6                 1.00  \n",
       "7                 0.16  \n",
       "8                 0.05  \n",
       "9                 0.22  \n",
       "\n",
       "[10 rows x 104 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['highCrime'] = (df['ViolentCrimesPerPop'] > 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     1250\n",
       "False     743\n",
       "Name: highCrime, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.highCrime.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Checking if the above counts are right\n",
    "p=sum(df['ViolentCrimesPerPop'][df['ViolentCrimesPerPop']>0.1].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1250"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p # right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#percentage of positive and negative:\n",
    "p1= df.highCrime.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     1250\n",
       "False     743\n",
       "Name: highCrime, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total=p1[0]+p1[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62.719518314099346"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Positive percentage:\n",
    "percentage_positive = p1[1]/total*100\n",
    "percentage_positive  \n",
    "# Output: 62.719518314099346"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37.280481685900654"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Negative percentage:\n",
    "percentage_negative = p1[0]/total*100\n",
    "percentage_negative  \n",
    "# Output: 37.280481685900654"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Percentage of positive instances : 62.72%\n",
    "Percentage of negative instances : 37.28%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Dividing data into train and test set\n",
    "X = df.drop(['communityname','ViolentCrimesPerPop','highCrime'],axis=1)\n",
    "y = df['highCrime']\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">There are some other columns that cannot be considered as features, such as fold, state."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Why did you split the data into train and test split? This was not asked."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting on X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Building Decision tree classifier\n",
    "from sklearn import tree\n",
    "dtc = tree.DecisionTreeClassifier(criterion = 'entropy')\n",
    "dtc = dtc.fit(X_train, y_train)\n",
    "\n",
    "y=dtc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy=  0.779448621554\n",
      "Precision=  0.848979591837\n",
      "Recall=  0.803088803089\n",
      "f1-score=  0.825396825397\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score,precision_score,recall_score, f1_score\n",
    "print(\"Accuracy= \",accuracy_score(y_test,y))\n",
    "print(\"Precision= \",precision_score(y_test,y)) \n",
    "print(\"Recall= \",recall_score(y_test,y)) \n",
    "print(\"f1-score= \",f1_score(y_test,y))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "predicting on X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y1=dtc.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy=  1.0\n",
      "Precision=  1.0\n",
      "Recall=  1.0\n",
      "f1-score=  1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score,precision_score,recall_score, f1_score\n",
    "print(\"Accuracy= \",accuracy_score(y_train,y1))\n",
    "print(\"Precision= \",precision_score(y_train,y1)) \n",
    "print(\"Recall= \",recall_score(y_train,y1)) \n",
    "print(\"f1-score= \",f1_score(y_train,y1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dimensions= list(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.01517591,  0.01043863,  0.01025166,  0.00797971,  0.00525841,\n",
       "        0.08782887,  0.        ,  0.06699369,  0.        ,  0.00522777,\n",
       "        0.00932864,  0.02020872,  0.        ,  0.        ,  0.00493345,\n",
       "        0.00665216,  0.00442474,  0.        ,  0.00654056,  0.01271924,\n",
       "        0.00255716,  0.00370645,  0.        ,  0.00815736,  0.01114912,\n",
       "        0.        ,  0.        ,  0.01418764,  0.00461075,  0.00384795,\n",
       "        0.        ,  0.01018966,  0.01536211,  0.00478531,  0.00376529,\n",
       "        0.        ,  0.00593365,  0.01342649,  0.        ,  0.00904565,\n",
       "        0.00757717,  0.        ,  0.01550128,  0.01447228,  0.00672013,\n",
       "        0.00425537,  0.31632095,  0.00555131,  0.00705875,  0.00743447,\n",
       "        0.        ,  0.00856699,  0.        ,  0.0070006 ,  0.01437725,\n",
       "        0.00791747,  0.00994184,  0.        ,  0.00461081,  0.        ,\n",
       "        0.00296969,  0.        ,  0.01084518,  0.0085545 ,  0.        ,\n",
       "        0.00131132,  0.        ,  0.00421877,  0.00529336,  0.00946775,\n",
       "        0.0043298 ,  0.00515236,  0.        ,  0.01749383,  0.00316976,\n",
       "        0.        ,  0.00180627,  0.00686554,  0.01529559,  0.        ,\n",
       "        0.0106901 ,  0.        ,  0.        ,  0.00554211,  0.00775781,\n",
       "        0.        ,  0.        ,  0.00678941,  0.00494108,  0.        ,\n",
       "        0.01111037,  0.0033504 ,  0.        ,  0.00427379,  0.00275456,\n",
       "        0.        ,  0.01112621,  0.00318306,  0.00487075,  0.00484323,\n",
       "        0.        ,  0.        ])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtc.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.31632095236026891, 'PctKids2Par'),\n",
       " (0.087828869739432186, 'racePctWhite'),\n",
       " (0.066993685521093083, 'racePctHisp'),\n",
       " (0.020208723910586056, 'agePct65up'),\n",
       " (0.017493834030438686, 'HousVacant')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "significance = dtc.feature_importances_\n",
    "f=zip(significance, dimensions)\n",
    "l=sorted(f, reverse=True)\n",
    "l[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "PctKids2Par, racePctWhite, racePctHisp, HousVacant, blackPerCap are the most significant variables in this model. \n",
    "PctKids2Par- percentage of kids in family housing with two parents (numeric - decimal)\n",
    "racePctWhite- percentage of population that is caucasian (numeric - decimal)\n",
    "racePctHisp- percentage of population that is of hispanic heritage\n",
    "HousVacant- number of vacant households (numeric - decimal)\n",
    "blackPerCap- per capita income for african americans (numeric - decimal)\n",
    "\n",
    "Out of the above 5 factors, the first (PctKids2Par), makes sense. The higher percentage of kids in family housing could mean \n",
    "higher targets for crime and eventually higher crime rate.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy =  0.76101598207\n",
      "Mean Recall =  0.793141414141\n",
      "Mean Precision =  0.821633920357\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "accuracy =  cross_val_score(dtc, X_train, y_train, cv=10)\n",
    "precision =  cross_val_score(dtc, X_train, y_train, cv=10 , scoring = 'precision')\n",
    "recall =  cross_val_score(dtc, X_train, y_train, cv=10 , scoring = 'recall')\n",
    "print (\"Mean Accuracy = \", accuracy.mean())\n",
    "print (\"Mean Recall = \", recall.mean())\n",
    "print (\"Mean Precision = \", precision.mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result for accuracy after cross-validation is 75.59% as compared to 100% obtained on X_train. \n",
    "The reason for getting 100% earlier was that the model was trained on the same data set as it was tested on. 10-fold cross validation generates \"out of sample\" data, and when the model is tested on it, the average accuracy obviously redcues due to new and varying sample instances. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Now the problem is, you could use the entire data for X-validation. But you used only 4/5 of it. Generally, we don't spare data, when we do X-validation, because X-validation internally spare part of the data as test and does not use it in the training at every iteration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2: Linear Classification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy=  0.759398496241\n",
      "Precision=  0.922279792746\n",
      "Recall=  0.687258687259\n",
      "f1-score=  0.787610619469\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb=GaussianNB()\n",
    "gnb.fit(X_train, y_train)\n",
    "y=gnb.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score, f1_score\n",
    "print(\"Accuracy= \",accuracy_score(y_test,y))\n",
    "print(\"Precision= \",precision_score(y_test,y)) \n",
    "print(\"Recall= \",recall_score(y_test,y)) \n",
    "print(\"f1-score= \",f1_score(y_test,y))\n",
    "\n",
    "\n",
    "#Accuracy=  0.759398496241\n",
    "#Precision=  0.922279792746\n",
    "#Recall=  0.687258687259\n",
    "#f1-score=  0.787610619469"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy =  0.77728204715\n",
      "Mean Recall =  0.695262626263\n",
      "Mean Precision =  0.929646088276\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "accuracy =  cross_val_score(gnb, X_train, y_train, cv=10)\n",
    "precision =  cross_val_score(gnb, X_train, y_train, cv=10 , scoring = 'precision')\n",
    "recall =  cross_val_score(gnb, X_train, y_train, cv=10 , scoring = 'recall')\n",
    "print (\"Mean Accuracy = \", accuracy.mean())\n",
    "print (\"Mean Recall = \", recall.mean())\n",
    "print (\"Mean Precision = \", precision.mean())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Mean Accuracy =  0.77728204715\n",
    "#Mean Recall =  0.695262626263\n",
    "#Mean Precision =  0.929646088276\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dimension</th>\n",
       "      <th>Significance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>PctKids2Par</td>\n",
       "      <td>0.809336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>PctFam2Par</td>\n",
       "      <td>0.745162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>racePctWhite</td>\n",
       "      <td>0.734884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>PctIlleg</td>\n",
       "      <td>0.708929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>FemalePctDiv</td>\n",
       "      <td>0.693604</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Dimension  Significance\n",
       "46   PctKids2Par      0.809336\n",
       "45    PctFam2Par      0.745162\n",
       "5   racePctWhite      0.734884\n",
       "52      PctIlleg      0.708929\n",
       "42  FemalePctDiv      0.693604"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l= X.columns\n",
    "d = pd.DataFrame({\"Dimension\": [], \"Significance\": []})\n",
    "\n",
    "for i in l:\n",
    "    means = df.groupby('highCrime')[i].mean()\n",
    "    variance = df.groupby('highCrime')[i].var()\n",
    "    \n",
    "    d = d.append({\"Dimension\": i, \"Significance\": abs(means[0] - means[1])/ sum(np.sqrt(variance))}, ignore_index=True)\n",
    " \n",
    "d.iloc[np.argsort(d['Significance'])[::-1][0:5], ]\n",
    "\n",
    "\n",
    "\n",
    "#Most significant variables identified = PctKids2Par,PctFam2Par, racePctWhite, PctIlleg, FemalePctDiv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PctKids2Par, PctFam2Par, racePctWhite, PctIlleg,FemalePctDiv are the most significant variables identified\n",
    "PctKids2Par- percentage of kids in family housing with two parents (numeric - decimal)\n",
    "PctFam2Par - percentage of families (with kids) that are headed by two parents (numeric - decimal)\n",
    "racePctWhite - percentage of population that is caucasian (numeric - decimal)\n",
    "PctIlleg - percentage of kids born to never married (numeric - decimal) \n",
    "FemalePctDiv - percentage of females who are divorced (numeric - decimal)\n",
    "\n",
    "Out of the above 6 factors, the first (PctKids2Par) and the 2nd (PctFam2Par) make sense and is consistent with what was observed in the earlier decision tree. The higher percentage of kids in family housing with 2 parents could mean \n",
    "higher targets for crime and eventually higher crime rate. And higher the percentage of such households would linearly increase/decrease the targets.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> It would be nice to mention the formula, and discuss why it make sense to calculate the distance between two means and then to divide by the summation of standard deviations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Just a presentation issue: Some subsection titles would be helpful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "svc =LinearSVC()\n",
    "svc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy =  0.781777974726\n",
      "Mean Recall =  0.87397979798\n",
      "Mean Precision =  0.88491157796\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "accuracy = cross_val_score(svc, X_train, y_train,cv=10,scoring=\"accuracy\")\n",
    "recall = cross_val_score(svc,X_train, y_train,cv=10,scoring=\"recall\")\n",
    "precision = cross_val_score(svc, X_train, y_train,cv=10,scoring=\"precision\")\n",
    "print (\"Mean Accuracy = \", accuracy.mean())\n",
    "print (\"Mean Recall = \", recall.mean())\n",
    "print (\"Mean Precision = \", precision.mean())\n",
    "\n",
    "\n",
    "#Mean Accuracy =  0.796103094847\n",
    "#Mean Recall =  0.821282828283\n",
    "#Mean Precision =  0.84267155864"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1.0715027620433351, 'MalePctDivorce'),\n",
       " (0.94507439573333485, 'racepctblack'),\n",
       " (0.92514278499990166, 'PctOccupMgmtProf'),\n",
       " (0.91124938062367722, 'agePct12t21'),\n",
       " (0.90133011980324307, 'racePctHisp')]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dimensions =list(X_train)\n",
    "weights =svc.coef_\n",
    "weights=weights[0]\n",
    "f= zip(weights, dimensions)\n",
    "l=sorted(f, reverse=True)\n",
    "l[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "MalePctDivorce, racepctblack, PctOccupMgmtProf, agePct12t21, racePctHisp are the most significant variables identified.\n",
    "MalePctDivorce - percentage of population who are divorced (numeric - decimal)\n",
    "racepctblack - percentage of population that is african american (numeric - decimal)\n",
    "PctOccupMgmtProf - percentage of people 16 and over who are employed in management or professional occupations (numeric - decimal)\n",
    "agePct12t21 - percentage of population that is 12-21 in age (numeric - decimal)\n",
    "racePctHisp- percentage of population that is of hispanic heritage (numeric - decimal)\n",
    "\n",
    "Out of the above features identified, the ones that make sense are PctOccupMgmtProf and agePct12t21. This is because, people in this \n",
    "age range and occupations are likely to be outside their homes during the day, hence they could be potential targets. Difference \n",
    "in the values of these features will make an impact on the predcited variable.\n",
    "\n",
    "\n",
    "No parameters between this model and Gaussian Naive Bayes models are similar. Only one paramter, which is racePctHisp,\n",
    "is common between this model and decision trees. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> This is an important observation and it would be nice to elaborate why SVM and GNB make use of different attributes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3: Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = df.drop(['communityname','ViolentCrimesPerPop','highCrime'],axis=1)\n",
    "y = df['ViolentCrimesPerPop']\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Same two remarks as above: There are some other columns to be discarded and why did you arbitrarily split the data into training and test sets?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lm=LinearRegression()\n",
    "lm.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of MSE:  0.133018201262\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "mse =  cross_val_score(lm, X_train, y_train, cv=10 , scoring = 'neg_mean_squared_error')  \n",
    "print (\"Mean of MSE: \", abs(mse.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> There is a mistake here: You train lm on the training set (X_train, y_train). Then you call cross_val_score() routine to run X-validation on your model. This routine internally trains the input model, which you give as your previously trained model lm. I am not sure. This may or may not be a problem. But if linear regression model here allows incremental training, that is, fit() function, once called for the second time, trains the model where it was left off at the end of the first training, then this X-validation you called here is not independent from your initial training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE on the training set:   0.4601785489173281\n"
     ]
    }
   ],
   "source": [
    "y =lm.predict(X_train)\n",
    "m=sum((y-y_train)**2)/len(y_test)\n",
    "print(\"MSE on the training set:  \",m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> I think this result deserves some discussion. The X-validation MSE is better than the individual MSE. Isn't it surprising? X-validation uses subsets of the same data. So the training set shrank but the MSE has increased, especially being test on a data that was not used in training. This difference is quite interesting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "population- 3.706893 - True\n",
      "numbUrban- 2.378423 - False\n",
      "PctKids2Par- 1.459143 - False\n",
      "PctRecImmig10- 1.114016 - False\n",
      "pctWInvInc- 1.007788 - False\n",
      "PctOccupMgmtProf- 0.930633 - True\n",
      "MedRent- 0.885291 - False\n",
      "PersPerOccupHous- 0.847443 - True\n",
      "NumIlleg- 0.824601 - False\n",
      "PctRecImmig5- 0.811896 - True\n"
     ]
    }
   ],
   "source": [
    "coeffecients = lm.coef_\n",
    "s = coeffecients >= 0\n",
    "abs_coeffecients=abs(lm.coef_)\n",
    "i = np.argsort(abs_coeffecients)[::-1]\n",
    "for f in range(10):\n",
    "    print(\"%s- %f - %s\" % (X_train.columns[i[f]], abs_coeffecients[i[f]], s[i[f]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predcitors of High crimes:\n",
    "\n",
    "1. PctHousOwnOcc\n",
    "2. MalePctDivorce\n",
    "3. PctRecImmig8\n",
    "4. PersPerOccupHous\n",
    "5. MedRent\n",
    "\n",
    "\n",
    "Predictors of low crimes:\n",
    "\n",
    "1. PctPersOwnOccup\n",
    "2. TotalPctDiv\n",
    "3. whitePerCap\n",
    "4. OwnOccLowQuart\n",
    "5. numbUrban"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RidgeCV(alphas=(10, 1, 0.1, 0.01, 0.001), cv=10, fit_intercept=True,\n",
       "    gcv_mode=None, normalize=False, scoring=None, store_cv_values=False)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import RidgeCV\n",
    "rm = RidgeCV(alphas=(10,1,0.1,0.01,0.001),cv=10)\n",
    "rm.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of MSE:  0.129886377108\n"
     ]
    }
   ],
   "source": [
    "m =  cross_val_score(rm, X_train, y_train, cv=10 , scoring = 'neg_mean_squared_error')  \n",
    "print (\"Mean of MSE: \", abs(m.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Same problem I described above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE on the training set:   0.46879732884269815\n"
     ]
    }
   ],
   "source": [
    "y =rm.predict(X_train)\n",
    "m=sum((y-y_train)**2)/len(y_test)\n",
    "print(\"MSE on the training set:  \",m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Alpha =  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Alpha = \",rm.alpha_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MSE for Linear regression: 0.0192\n",
    "MSE for Ridge regression: 0.0189\n",
    "The mean squared error can be interpreted as the closeness of the data points with the predcited regression line. This explains that Ridge regression is able to redcue overfitting to some extent compared to the result of linear regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Two things: (i) This is an extremely small difference (.0003) for a value that can range from 0 to 1. So it is hard to say the ridge regression helped to reduce overfitting. (ii) I ran your code and the values that I got are quite different than what you indicate here. How did you get these values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "poly_reg = PolynomialFeatures(degree=2)\n",
    "x_p =poly_reg.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'float' object has no attribute 'mean'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-45df6d1ccd34>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mplm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mLinearRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mqlr_cv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcross_val_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mplm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_p\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"neg_mean_squared_error\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"Mean of MSE: \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'float' object has no attribute 'mean'"
     ]
    }
   ],
   "source": [
    "plm=LinearRegression()\n",
    "qlr_cv=cross_val_score(plm, x_p, y_train,cv=10,scoring=\"neg_mean_squared_error\")\n",
    "print (\"Mean of MSE: \", abs(m.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> I ran this cell and got an exception. I copy this cell below, edit it and run again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of MSE:  0.802500478325\n"
     ]
    }
   ],
   "source": [
    "plm=LinearRegression()\n",
    "qlr_cv=cross_val_score(plm, x_p, y_train,cv=10,scoring=\"neg_mean_squared_error\")\n",
    "print (\"Mean of MSE: \", abs(qlr_cv.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Here we get the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE on the training set =  1.7711927142756484e-24\n"
     ]
    }
   ],
   "source": [
    "plm.fit(x_p,y_train)\n",
    "y=plm.predict(x_p)\n",
    "m=sum((y-y_train)**2)/len(y_train)\n",
    "print(\"MSE on the training set = \",m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MSE of quadratic model after 10 cross validation: 0.0676\n",
    "\n",
    "MSE of linear model after 10 cross validation: 0.0189\n",
    "\n",
    "Since the MSE of quadratic model is higher than the linear model, we conclude that the linear model is better than the quadratic model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> I checked results in your original submission. These are the values. But I have no idea how you got them. Did you edit the data file by any chance?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 4: Dirty data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>county</th>\n",
       "      <th>community</th>\n",
       "      <th>communityname</th>\n",
       "      <th>fold</th>\n",
       "      <th>population</th>\n",
       "      <th>householdsize</th>\n",
       "      <th>racepctblack</th>\n",
       "      <th>racePctWhite</th>\n",
       "      <th>racePctAsian</th>\n",
       "      <th>...</th>\n",
       "      <th>LandArea</th>\n",
       "      <th>PopDens</th>\n",
       "      <th>PctUsePubTrans</th>\n",
       "      <th>PolicCars</th>\n",
       "      <th>PolicOperBudg</th>\n",
       "      <th>LemasPctPolicOnPatr</th>\n",
       "      <th>LemasGangUnitDeploy</th>\n",
       "      <th>LemasPctOfficDrugUn</th>\n",
       "      <th>PolicBudgPerPop</th>\n",
       "      <th>ViolentCrimesPerPop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>Lakewoodcity</td>\n",
       "      <td>1</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.12</td>\n",
       "      <td>...</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>Tukwilacity</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.45</td>\n",
       "      <td>...</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.45</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>0.00</td>\n",
       "      <td>?</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>Aberdeentown</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.17</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.02</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>0.00</td>\n",
       "      <td>?</td>\n",
       "      <td>0.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34</td>\n",
       "      <td>5</td>\n",
       "      <td>81440</td>\n",
       "      <td>Willingborotownship</td>\n",
       "      <td>1</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.77</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.12</td>\n",
       "      <td>...</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.28</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>0.00</td>\n",
       "      <td>?</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>42</td>\n",
       "      <td>95</td>\n",
       "      <td>6096</td>\n",
       "      <td>Bethlehemtownship</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.09</td>\n",
       "      <td>...</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.02</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>0.00</td>\n",
       "      <td>?</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>SouthPasadenacity</td>\n",
       "      <td>1</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.54</td>\n",
       "      <td>1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.10</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>0.00</td>\n",
       "      <td>?</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>44</td>\n",
       "      <td>7</td>\n",
       "      <td>41500</td>\n",
       "      <td>Lincolntown</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.06</td>\n",
       "      <td>...</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.06</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>0.00</td>\n",
       "      <td>?</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>Selmacity</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.20</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.00</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>0.00</td>\n",
       "      <td>?</td>\n",
       "      <td>0.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>21</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>Hendersoncity</td>\n",
       "      <td>1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.02</td>\n",
       "      <td>...</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.04</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>0.00</td>\n",
       "      <td>?</td>\n",
       "      <td>0.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>29</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>Claytoncity</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.11</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>0.00</td>\n",
       "      <td>?</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 128 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   state county community        communityname  fold  population  \\\n",
       "0      8      ?         ?         Lakewoodcity     1        0.19   \n",
       "1     53      ?         ?          Tukwilacity     1        0.00   \n",
       "2     24      ?         ?         Aberdeentown     1        0.00   \n",
       "3     34      5     81440  Willingborotownship     1        0.04   \n",
       "4     42     95      6096    Bethlehemtownship     1        0.01   \n",
       "5      6      ?         ?    SouthPasadenacity     1        0.02   \n",
       "6     44      7     41500          Lincolntown     1        0.01   \n",
       "7      6      ?         ?            Selmacity     1        0.01   \n",
       "8     21      ?         ?        Hendersoncity     1        0.03   \n",
       "9     29      ?         ?          Claytoncity     1        0.01   \n",
       "\n",
       "   householdsize  racepctblack  racePctWhite  racePctAsian  \\\n",
       "0           0.33          0.02          0.90          0.12   \n",
       "1           0.16          0.12          0.74          0.45   \n",
       "2           0.42          0.49          0.56          0.17   \n",
       "3           0.77          1.00          0.08          0.12   \n",
       "4           0.55          0.02          0.95          0.09   \n",
       "5           0.28          0.06          0.54          1.00   \n",
       "6           0.39          0.00          0.98          0.06   \n",
       "7           0.74          0.03          0.46          0.20   \n",
       "8           0.34          0.20          0.84          0.02   \n",
       "9           0.40          0.06          0.87          0.30   \n",
       "\n",
       "          ...           LandArea  PopDens  PctUsePubTrans  PolicCars  \\\n",
       "0         ...               0.12     0.26            0.20       0.06   \n",
       "1         ...               0.02     0.12            0.45          ?   \n",
       "2         ...               0.01     0.21            0.02          ?   \n",
       "3         ...               0.02     0.39            0.28          ?   \n",
       "4         ...               0.04     0.09            0.02          ?   \n",
       "5         ...               0.01     0.58            0.10          ?   \n",
       "6         ...               0.05     0.08            0.06          ?   \n",
       "7         ...               0.01     0.33            0.00          ?   \n",
       "8         ...               0.04     0.17            0.04          ?   \n",
       "9         ...               0.00     0.47            0.11          ?   \n",
       "\n",
       "   PolicOperBudg  LemasPctPolicOnPatr  LemasGangUnitDeploy  \\\n",
       "0           0.04                  0.9                  0.5   \n",
       "1              ?                    ?                    ?   \n",
       "2              ?                    ?                    ?   \n",
       "3              ?                    ?                    ?   \n",
       "4              ?                    ?                    ?   \n",
       "5              ?                    ?                    ?   \n",
       "6              ?                    ?                    ?   \n",
       "7              ?                    ?                    ?   \n",
       "8              ?                    ?                    ?   \n",
       "9              ?                    ?                    ?   \n",
       "\n",
       "   LemasPctOfficDrugUn  PolicBudgPerPop  ViolentCrimesPerPop  \n",
       "0                 0.32             0.14                 0.20  \n",
       "1                 0.00                ?                 0.67  \n",
       "2                 0.00                ?                 0.43  \n",
       "3                 0.00                ?                 0.12  \n",
       "4                 0.00                ?                 0.03  \n",
       "5                 0.00                ?                 0.14  \n",
       "6                 0.00                ?                 0.03  \n",
       "7                 0.00                ?                 0.55  \n",
       "8                 0.00                ?                 0.53  \n",
       "9                 0.00                ?                 0.15  \n",
       "\n",
       "[10 rows x 128 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full = pd.read_csv('../Crime Prediction Data/communities-crime-full.csv')\n",
    "df_full[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     1251\n",
       "False     743\n",
       "Name: highCrime, dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full['highCrime'] = (df_full['ViolentCrimesPerPop'] > 0.1)\n",
    "df_full.highCrime.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Missing value treatment1 : replacing missing values with mean of the respective feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = df_full.drop(['communityname','ViolentCrimesPerPop','highCrime'],axis=1)\n",
    "X=X.apply(pd.to_numeric,errors='coerce')\n",
    "X = X.fillna(X.mean()).astype(int).astype(int)\n",
    "y = df_full['highCrime']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> This cell wasn't run. Why not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Building Decision tree classifier\n",
    "from sklearn import tree\n",
    "dtc = tree.DecisionTreeClassifier(criterion = 'entropy')\n",
    "dtc = dtc.fit(X_train, y_train)\n",
    "\n",
    "y=dtc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy =  0.757844105238\n",
      "Mean Recall =  0.789090909091\n",
      "Mean Precision =  0.819001472944\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "accuracy =  cross_val_score(dtc, X_train, y_train, cv=10)\n",
    "precision =  cross_val_score(dtc, X_train, y_train, cv=10 , scoring = 'precision')\n",
    "recall =  cross_val_score(dtc, X_train, y_train, cv=10 , scoring = 'recall')\n",
    "print (\"Mean Accuracy = \", accuracy.mean())\n",
    "print (\"Mean Recall = \", recall.mean())\n",
    "print (\"Mean Precision = \", precision.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Mean Accuracy =  0.76101598207 \n",
    ">Mean Recall =  0.793141414141\n",
    ">Mean Precision =  0.821633920357\n",
    ">These results are very close, but not identical. They are not identical, because there is a random seed in the cross_val_score routine and we cannot set it. This routing calls StratifiedKFold which requires the random seed (See cross_val_score doc)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1594, 102)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1994, 126)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Your new X has 126 columns, whereas your previous X_train has 102. You loaded the dirty data, and you did not use it. Instead you used the clean data. Why?\n",
    "\n",
    "> Let's see what these results would be if you used dirty data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [1994, 399]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-49-71f3830617a1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;34m'''Caner added this cell, copy of a previous cell'''\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m42\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[1;34m(*arrays, **options)\u001b[0m\n\u001b[0;32m   2013\u001b[0m         \u001b[0mtest_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.25\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2014\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2015\u001b[1;33m     \u001b[0marrays\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2016\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2017\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mshuffle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mindexable\u001b[1;34m(*iterables)\u001b[0m\n\u001b[0;32m    196\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m             \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 198\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    199\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    171\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[1;32m--> 173\u001b[1;33m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[0;32m    174\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [1994, 399]"
     ]
    }
   ],
   "source": [
    "'''Caner added this cell, copy of a previous cell'''\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Your y and X did not have the same number of instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Missing value treatment 2: replacing missing values with median of the respective feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = df_full.drop(['communityname','ViolentCrimesPerPop','highCrime'],axis=1)\n",
    "X=X.apply(pd.to_numeric,errors='coerce')\n",
    "X = X.fillna(X.median()).astype(int).astype(int)\n",
    "y = df_full['highCrime']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Now it ran this time, and I am not sure why it worked here, but it did not work previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy =  0.668975549319\n",
      "Mean Recall =  0.728159580664\n",
      "Mean Precision =  0.744445031026\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "accuracy =  cross_val_score(dtc, X_train, y_train, cv=10)\n",
    "precision =  cross_val_score(dtc, X_train, y_train, cv=10 , scoring = 'precision')\n",
    "recall =  cross_val_score(dtc, X_train, y_train, cv=10 , scoring = 'recall')\n",
    "print (\"Mean Accuracy = \", accuracy.mean())\n",
    "print (\"Mean Recall = \", recall.mean())\n",
    "print (\"Mean Precision = \", precision.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision tree could not be directly implemented with missing values. These missing values in the data had to be treated. There wer 2 approaches follwed:\n",
    "1. Replacing the missing values with mean of the respective feature\n",
    "2. Replacing the missing values with the median of the respective feature\n",
    "\n",
    "After 10 cross fold validation, the accuracy for the 1st and the 2nd approach were 67.146 and 66.273 respectively. This is much lower than the accuracy that was gotten in the clean data, which was 76.94%. Hence we see that the results are worse with missing values and conclude that missing values have negative imoact on model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (py36)",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
